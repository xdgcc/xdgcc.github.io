<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="从几只小爬虫开始"><meta name="keywords" content="Python"><meta name="author" content="ゴウサク"><meta name="copyright" content="ゴウサク"><title>从几只小爬虫开始 | Corner&amp;Coder</title><link rel="shortcut icon" href="/xdgcc.jpg"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.1.0'
} </script><meta name="generator" content="Hexo 6.1.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%9C%B0%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD%E7%88%AC%E8%99%AB"><span class="toc-number">1.</span> <span class="toc-text">简单地图片下载爬虫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0%E5%9C%A8%E7%BA%BF%E7%BF%BB%E8%AF%91"><span class="toc-number">2.</span> <span class="toc-text">通过爬虫实现在线翻译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">使用代理</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">ゴウサク</div><div class="author-info__description text-center">听听歌 码码字</div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/xdgcc">Follow Me In GitHub</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">21</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">13</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">8</span></a></div></div></div><div id="content-outer"><div class="plain" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Corner&amp;Coder</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div></div><div class="layout" id="content-inner"><article id="post"><div class="plain" id="post-title">从几只小爬虫开始</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2015-10-06</time><span class="post-meta__separator">|</span><i class="fa fa-inbox" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Python/"> Python</a><span class="post-meta__separator">|</span><span class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">1.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 6 分钟</span></span></div><div class="article-container" id="post-content"><hr>
<blockquote>
<p>人生苦短，我用Python。</p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://reliscore.com/blog/why-every-programmer-should-learn-python-or-ruby/">Why every programmer should learn Python or Ruby</a></p>
</blockquote>
<p>更新记录</p>
<p>2015-10-12 使用代理</p>
<hr>
<h3 id="简单地图片下载爬虫"><a href="#简单地图片下载爬虫" class="headerlink" title="简单地图片下载爬虫"></a>简单地图片下载爬虫</h3><p>废话不多说，来看第一个例程。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">req = urllib.request.urlopen(<span class="string">&#x27;http://placekitten.com/g/500/600&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(req)</span><br><span class="line"></span><br><span class="line">cat_img = response.read()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;cat_500_600.jpg&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	f.write(cat_img)</span><br></pre></td></tr></table></figure>

<p>这是最初级的一个实例，上面这个爬虫从这个<a target="_blank" rel="noopener" href="http://placekitten.com/">猫奴网站</a>下载了一可爱的小猫。这算是最简单的一个python爬虫了，只用到了一个urlopen方法。</p>
<p>通过上面的例程搞懂以下几个问题：</p>
<ul>
<li>urllib模块有什么作用</li>
<li>urlopen函数的使用</li>
<li>文件的open操作</li>
<li>with语句的用法</li>
</ul>
<p>查阅一番资料和Python的API文档，可以得到以下答案：</p>
<ul>
<li><p>urllib模块是Python的一个获取url（Uniform Resource Locators，统一资源定址器）的模块。</p>
</li>
<li><p>urlopen函数提供了一个非常简洁的接口，使得Python用各种各样的协议获取url。对请求的url返回一个response对象。这个response是一个file-like的对象，能用.read()函数操作这个response对象。</p>
</li>
<li><p>**fp &#x3D; open(“文件名”,打开模式)**直接打开一个文件，如果文件不存在则创建文件</p>
</li>
</ul>
<blockquote>
<p><img src="http://image.dapaner.top/Snip20151007_17.png" alt="图一"></p>
</blockquote>
<ul>
<li>with 语句是从 Python 2.5 开始引入的一种与<strong>异常处理</strong>相关的功能,从 2.6 版本开始缺省可用（参考 What’s new in Python 2.6? 中 with 语句相关部分介绍）。with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。——源自<a target="_blank" rel="noopener" href="http://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/">《浅谈 Python 的 with 语句》</a></li>
</ul>
<hr>
<h3 id="通过爬虫实现在线翻译"><a href="#通过爬虫实现在线翻译" class="headerlink" title="通过爬虫实现在线翻译"></a>通过爬虫实现在线翻译</h3><p>在有了以上基础以后，开始摸索更为复杂的爬虫。第二个例程要实现通过爬虫使用有道词典的在线翻译。</p>
<p>还是先上源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">content = <span class="built_in">input</span>(<span class="string">&quot;what do you want to translate?&quot;</span>)</span><br><span class="line">url = <span class="string">&#x27;http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null&#x27;</span></span><br><span class="line">data = &#123;&#125;</span><br><span class="line">data[<span class="string">&#x27;type&#x27;</span>] = <span class="string">&#x27;AUTO&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;i&#x27;</span>] = content</span><br><span class="line">data[<span class="string">&#x27;doctype&#x27;</span>] = <span class="string">&#x27;json&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;xmlVersion&#x27;</span>] = <span class="string">&#x27;1.8&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;keyfrom&#x27;</span>] = <span class="string">&#x27;fanyi.web&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;ue&#x27;</span>] = <span class="string">&#x27;UTF-8&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;action&#x27;</span>] = <span class="string">&#x27;FY_BY_CLICKBUTTON&#x27;</span></span><br><span class="line">data[<span class="string">&#x27;typoResult&#x27;</span>] = <span class="string">&#x27;true&#x27;</span></span><br><span class="line"></span><br><span class="line">data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(url, data)</span><br><span class="line">html = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">json.loads(html)</span><br><span class="line">target = json.loads(html)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;result:%s&quot;</span>% (target[<span class="string">&#x27;translateResult&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="string">&#x27;tgt&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<p>比第一个复杂了好多。不着急，一行一行看。</p>
<p>相比于第一个例程里只有urllib.request模块，这次我们多导入了两个模块<strong>urllib.parse</strong>和<strong>json</strong>。先不管这些，让我们先来分析一下如何实现使用有道词典的在线翻译。</p>
<p>打开Chrome进入有道翻译的页面，我们先简单看一下翻译“i love you”时，浏览器与服务器之间的交互，顺便了解我们的代码。</p>
<p>进入“审查元素”页面，我们在输入完“i love you”之后点击翻译，看到“Network”下一大堆浏览器与服务器之间的交互。</p>
<p><img src="http://image.dapaner.top/Snip20151007_18.png" alt="图二"></p>
<p>我们点击进入第一个浏览器向服务器提交的POST请求，来分析下想要用代码模拟人的操作，需要些什么。</p>
<p><img src="http://image.dapaner.top/Snip20151006_11.png" alt="图三"><br><img src="http://image.dapaner.top/Snip20151006_12.png" alt="图四"></p>
<p>如上图所示，我们要代码实现交互，就要模拟浏览器，向服务器提交POST。那么如何完成呢，就要接住urlopen这个函数了。查看API文档，我们找到urlopen这个函数，看看他到底是如何使用的：</p>
<p><img src="http://image.dapaner.top/Snip20151006_13.png" alt="图五"></p>
<p>urlopen函数在定义时可以传两个参数分别为<strong>url</strong>和<strong>data</strong>。url为我们实际需要访问的链接，这里要特别注意，url参数的值必须为图三中的Request URL梭织链接，而并非浏览器地址栏中的url。而data参数为字典类型，内容就是我们要向服务器提交的POST内容，也就是图四中From Data的内容了，于是我们在代码（第6~16行）中直接定义即可。</p>
<p>这里还有一点需要注意，在代码的第18行，有关字符编码。我们的POST要以字符串编码的形式提交，而我们定义的却是字典类型的数据，这时候就要借助urllib.parse模块中的**urlencode()**函数来实现转义。格式为“utf-8”（.encode(‘utf-8’)）。</p>
<p><img src="http://image.dapaner.top/Snip20151007_20.png" alt="图六"></p>
<p>好了。在爬取网页之前的准备工作就已经全部完成了，接下来我们进行爬取并打印response对象的内容：</p>
<p><img src="http://image.dapaner.top/Snip20151006_14.png" alt="图七"></p>
<p>没有错，我们获得了json格式的内容，那什么是json，json模块中有哪些函数，它们又如何使用？</p>
<p><img src="http://image.dapaner.top/Snip20151007_21.png"><br><img src="http://image.dapaner.top/Snip20151007_22.png" alt="图八"></p>
<p>接下来就是从json数据中提取出我们想要的内容了。使用**json.loads()**提取出字典后，打印就好了。</p>
<p><img src="http://image.dapaner.top/Snip20151006_15.png" alt="图九"></p>
<p>最后来测试下整体的效果：</p>
<p><img src="http://image.dapaner.top/Snip20151007_23.png" alt="图十"></p>
<hr>
<h3 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h3><p>当我们用python爬虫进行一些比较密集的爬取（比如下载某网站的所有图片啊）时，服务器会对我们进行封锁，那么我们要如何继续疯狂的爬啊爬呢？</p>
<p>没有错，就是使用代理。我们用很多个不同的ip地址去登陆服务器，这样服务器就会误认为是很多个不同的人在链接，所以就不会封锁你咯。再搭配上面提到的对Headers的设置，我们就可以快速的进行爬取了。</p>
<p>在Python中使用代理一共有如下几步：</p>
<ul>
<li>设置一个字典作为参数，要这样的格式：{‘类型’:‘代理ip:端口号’}</li>
<li>调用urllib.request.ProxyHandler()方法，传入我们刚刚设置的字典参数</li>
<li>定制、创建我们的opener，用来获取url</li>
<li>安装我们“私人定制”的opener</li>
<li>调用opener</li>
</ul>
<p>呐，知道了这些，我们就来实践一下，使用代理来访问一个宝岛台湾的网站<a target="_blank" rel="noopener" href="http://www.whatismyip.com.tw/">whatismyip</a>,这是一个很有意思的玩意儿，这个网站只有一个作用那就是显示你当前访问它使用的IP地址。</p>
<p>好，先来看看代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.whatismyip.com.tw&#x27;</span></span><br><span class="line"></span><br><span class="line">iplist = [<span class="string">&#x27;222.88.236.236:843&#x27;</span>,<span class="string">&#x27;125.131.193.43:80&#x27;</span>,<span class="string">&#x27;183.252.18.131:8080&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">proxy_support = urllib.request.ProxyHandler(&#123;<span class="string">&#x27;http&#x27;</span>:random.choice(iplist)&#125;)</span><br><span class="line"></span><br><span class="line">opener = urllib.request.build_opener(proxy_support)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">opener.addheaders = [(<span class="string">&#x27;User-Agent&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.152 Safari/537.36&#x27;</span>)]</span><br><span class="line">urllib.request.install_opener(opener)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line">html = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(html)</span><br></pre></td></tr></table></figure>

<p>我们还是一句一句的来分析，首先是我们要访问的域名，不多说。往下走，我们新建一个列表，来储存待用的ip地址。至于代理ip的话，网上有好多，百度一下，copy过来。</p>
<p>接下来我们定义了一个proxy_support，后面用的是urllib.request.ProxyHandler()方法，从这一句开始，我们开始使用代理。然后我们自定义了一个opener，并且安装了它</p>
<p>还是从文档开始看起：</p>
<p><img src="http://image.dapaner.top/Snip20151012_54.png" alt="图十一"><br><img src="http://image.dapaner.top/Snip20151012_55.png" alt="图十二"></p>
<p>功能就是大概我们描述的样子。接下来的的大家都已经熟悉了，最后我们打印获得的网页HTML源码，来看我们到底用了什么ip地址去访问：</p>
<p><img src="http://image.dapaner.top/Snip20151012_56.png" alt="图十三"></p>
<p>再运行一次，看看，两次的访问ip可是不一样的咧。</p>
<p><img src="http://image.dapaner.top/Snip20151012_57.png" alt="图十四"></p>
<p>需要注意的一点是，这些代理ip可是每天都在变得，如果如果你想运行参考例程，最好是重新搜一下代理ip并更新代码中的iplist。</p>
<hr>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">ゴウサク</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://dapaner.top/2015/10/06/从几只小爬虫开始/">http://dapaner.top/2015/10/06/从几只小爬虫开始/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://dapaner.top">Corner&Coder</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/wechatpay.jpg"><div class="post-qr-code__desc">微信赞赏码</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/alipay.jpg"><div class="post-qr-code__desc">支付宝赞赏码</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2015/10/12/iOS%E5%BC%80%E5%8F%91%E2%80%94%E2%80%94Storyboard%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BD%AC/"><i class="fa fa-chevron-left">  </i><span>Storyboard页面跳转</span></a></div><div class="next-post pull-right"><a href="/2015/10/04/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%AE%8C%E5%85%A8Mac%E5%AE%89%E8%A3%85Scrapy%E6%8C%87%E5%8D%97/"><span>史上最完全Mac安装Scrapy指南</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '84913d96f60653d72440',
  clientSecret: '82a93cdaf171e21c709424447f3a207b107faddd',
  repo: 'xdgcc.github.io',
  owner: 'xdgcc',
  admin: 'xdgcc',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2015 - 2022 By ゴウサク</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="http://www.beian.miit.gov.cn">粤ICP备19063859号</a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>